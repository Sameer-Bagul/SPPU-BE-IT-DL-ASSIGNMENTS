{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d8274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 00:24:18.313968: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-07 00:24:18.314233: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-07 00:24:18.353614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-07 00:24:19.382990: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-07 00:24:19.383347: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd4ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'data/caltech-101-img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71df5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_datagen = ImageDataGenerator(rescale=1.0 / 255,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e238b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9144 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2000\n",
    "dataset_generator = dataset_datagen.flow_from_directory(\n",
    "dataset_dir,\n",
    "target_size=(64, 64),\n",
    "batch_size=batch_size,\n",
    "class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f534cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = dataset_generator[0]\n",
    "x_test, y_test = dataset_generator[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a4b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf5cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# weights_path = 'data/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weights_path = 'data/vgg/vgg16_weights_tf_dim_ordering_tf_kernels_notop (1).h5'\n",
    "print(os.path.exists(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5230f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762455576.361262  137659 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762455576.370911  137659 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "weights_path = 'data/vgg/vgg16_weights_tf_dim_ordering_tf_kernels_notop (1).h5'\n",
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ec9c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c8be4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(102, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ecf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ef79951",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5858d219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 900ms/step - accuracy: 0.2305 - loss: 3.8239 - val_accuracy: 0.2960 - val_loss: 3.3507\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.3810 - loss: 2.9160 - val_accuracy: 0.3875 - val_loss: 2.9488\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.4790 - loss: 2.4376 - val_accuracy: 0.4195 - val_loss: 2.6827\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5570 - loss: 2.0648 - val_accuracy: 0.4925 - val_loss: 2.4364\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6195 - loss: 1.7687 - val_accuracy: 0.4985 - val_loss: 2.3198\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.6735 - loss: 1.5352 - val_accuracy: 0.5145 - val_loss: 2.1814\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.7165 - loss: 1.3248 - val_accuracy: 0.5245 - val_loss: 2.1286\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.7635 - loss: 1.1630 - val_accuracy: 0.5525 - val_loss: 2.0189\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.7930 - loss: 1.0277 - val_accuracy: 0.5540 - val_loss: 1.9795\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.8170 - loss: 0.9127 - val_accuracy: 0.5625 - val_loss: 1.9332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x797ce1dfe1a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "935cb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c520325",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc767afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[len(base_model.layers) - 2:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8bc4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "predictions = Dense(102, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cd7366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8771666",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1d55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 973ms/step - accuracy: 0.3625 - loss: 3.1130 - val_accuracy: 0.4490 - val_loss: 2.4282\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.5695 - loss: 1.7847 - val_accuracy: 0.5455 - val_loss: 1.9493\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.7045 - loss: 1.1613 - val_accuracy: 0.5845 - val_loss: 1.7638\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.8185 - loss: 0.6770 - val_accuracy: 0.5970 - val_loss: 1.7942\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.8755 - loss: 0.4224 - val_accuracy: 0.5945 - val_loss: 1.7918\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9135 - loss: 0.3059 - val_accuracy: 0.6275 - val_loss: 1.7984\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9450 - loss: 0.1946 - val_accuracy: 0.6260 - val_loss: 1.8380\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.9722 - loss: 0.1217"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc882f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predicted_value = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(dataset_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[60])\n",
    "print(\"Preditcted: \",labels[np.argmax(predicted_value[60])])\n",
    "print(\"Actual: \", labels[np.argmax(y_test[60])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab057127",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Accuracy is {acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
